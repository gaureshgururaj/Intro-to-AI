{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We walk through a vanilla AutoEncoder on the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from svlearn.auto_encoders.vanilla_auto_encoder_mnist import (AutoencoderMnist,\n",
    "                                                        train_autoencoder,\n",
    "                                                        visualize_reconstruction,\n",
    "                                                        get_latent_representations\n",
    ")\n",
    "from svlearn.auto_encoders.auto_encoder_util import (   sample_from_gmm,\n",
    "                                                        generate_images_from_latent,\n",
    "                                                        visualize_generated_images,\n",
    "                                                        visualize_interpolations)\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the path for mnist data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_path = '/home/chandar/data'\n",
    "model_path = '/home/chandar/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root=mnist_data_path, train=True, download=True, transform=None)\n",
    "\n",
    "train_dataset = mnist_trainset.data[:-10000].reshape(-1, 1, 28, 28) / 255.\n",
    "eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(eval_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify device (either cuda or cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoencoderMnist().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training on the vanilla autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train autoencoder\n",
    "train_autoencoder(model, train_loader, val_loader, num_epochs=10, learning_rate=1e-3, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the reconstruction (top row being original images and bottom being reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random shuffles of the val loader to visualize different samples each time.\n",
    "val_loader = DataLoader(eval_dataset, batch_size=128, shuffle=True) \n",
    "# Call this to monitor reconstruction\n",
    "visualize_reconstruction(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate images from hidden vectors using the decoder of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect latent representations from training data\n",
    "latent_data = get_latent_representations(model, train_loader, device=device)\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 10 components\n",
    "gmm = GaussianMixture(n_components=10)\n",
    "gmm.fit(latent_data)\n",
    "\n",
    "# Sample from the GMM\n",
    "latent_samples = sample_from_gmm(gmm, num_samples=10)\n",
    "\n",
    "# Generate images from the latent samples\n",
    "generated_images = generate_images_from_latent(model, latent_samples, device=device)\n",
    "\n",
    "# Visualize the generated images\n",
    "visualize_generated_images(generated_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize interpolations between the reconstruction of two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create random shuffle of train dataset to pick random 2 images every time.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "first_train_batch = next(iter(train_loader))\n",
    "# Visualize interpolations\n",
    "# Assuming image1 and image2 are samples from your dataset (PIL images already transformed to tensor)\n",
    "image1 = first_train_batch[0]  # First image\n",
    "image2 = first_train_batch[1]  # Second image\n",
    "\n",
    "# Visualize interpolation between the two images\n",
    "visualize_interpolations(model, image1, image2, num_steps=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_intro_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
