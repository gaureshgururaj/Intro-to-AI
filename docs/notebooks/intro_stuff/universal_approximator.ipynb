{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:14:20.074918605Z",
     "start_time": "2023-06-09T21:14:19.435745306Z"
    }
   },
   "outputs": [],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks as Universal Approximators\n",
    "\n",
    "In the theory session, we learned that the neural networks are universal approximators. In this lab, we are going to verify with a few simple univariate function examples that this is indeed true.\n",
    "\n",
    "To make it easier to play around with the concept, use the ``UnivariateApproximator`` class in the ``svlearn.approximator`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:14:21.983947805Z",
     "start_time": "2023-06-09T21:14:21.422426513Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from typing import Callable, List\n",
    "from svlearn.approximator.univariate_approximator import (UnivariateApproximator, \n",
    "                                                          UnivariatePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:14:22.166411060Z",
     "start_time": "2023-06-09T21:14:22.163358122Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:14:22.795222823Z",
     "start_time": "2023-06-09T21:14:22.790783692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore this for now, till we learn about dashboards.\n",
    "#import wandb\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sigmoid-like function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:15:20.043555994Z",
     "start_time": "2023-06-09T21:15:08.460292700Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_like = lambda x: 1/(1.0 + np.exp(10-15*x)) \n",
    "    \n",
    "approximator = UnivariateApproximator(sigmoid_like)\n",
    "approximator.train(1)\n",
    "approximator.evaluate_model()\n",
    "correlation = approximator.correlation()\n",
    "print(f'The Pearson correlation between ground truth and prediction is {correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the original function and its neural approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:15:20.251677636Z",
     "start_time": "2023-06-09T21:15:20.043809545Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = approximator.create_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T07:32:17.881986Z",
     "start_time": "2020-09-14T07:32:05.892577Z"
    }
   },
   "source": [
    "# A Wierd function\n",
    "\n",
    "Let us now consider something more complex:\n",
    "\n",
    "\\begin{equation}\n",
    "    y = (7 - 5 x + x^2 - 1.5 x^3) \\sin(10 x^2) \n",
    "\\end{equation}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:15:57.831184345Z",
     "start_time": "2023-06-09T21:15:29.443251957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the complex function\n",
    "wierd_x = lambda x:  (7 - 5 * x + x * x - 1.5 * x ** 3)* np.sin(10*x * x)\n",
    "approximator = UnivariateApproximator(wierd_x)\n",
    "approximator.train(1)\n",
    "\n",
    "# Now evaluate the model, and plot it\n",
    "approximator.evaluate_model()\n",
    "correlation = approximator.correlation()\n",
    "print(f'The Pearson correlation between ground truth and prediction is {correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:15:58.025423966Z",
     "start_time": "2023-06-09T21:15:57.837194027Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = approximator.create_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinc (x)\n",
    "\n",
    "Consider a function:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\frac{\\sin(3 x)}{x}\n",
    "\\end{equation}\n",
    "\n",
    "Let us consider this function over the domain of $x \\in [0,1]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:16:24.860480109Z",
     "start_time": "2023-06-09T21:15:58.026111338Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define the function\n",
    "def xsinx (x: float) -> float:\n",
    "    return np.sinc(3*x)\n",
    "\n",
    "approximator = UnivariateApproximator(xsinx)\n",
    "approximator.train(1)\n",
    "approximator.evaluate_model()\n",
    "correlation = approximator.correlation()\n",
    "print(f'The Pearson correlation between ground truth and prediction is {correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the original function and its neural approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:16:25.051835913Z",
     "start_time": "2023-06-09T21:16:24.866215669Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = approximator.create_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interesting function\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\sin(2 \\sin(2 \\sin(2 \\sin(10 x))))\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T19:36:14.203074Z",
     "start_time": "2022-05-18T19:35:41.013869Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the function\n",
    "def to_many_sines (x: float) -> float:\n",
    "    return np.sin (2*np.sin(2*np.sin(2*np.sin(10*x))))\n",
    "\n",
    "approximator = UnivariateApproximator(to_many_sines)\n",
    "approximator.train(1)\n",
    "approximator.evaluate_model()\n",
    "correlation = approximator.correlation()\n",
    "print(f'The Pearson correlation between ground truth and prediction is {correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the original function and its neural approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T19:36:14.513084Z",
     "start_time": "2022-05-18T19:36:14.204490Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = approximator.create_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code walkthrough\n",
    "\n",
    "Carefully walk through the code in the `svlearn.approximator.univariate_approximator` python module. In particular, look at the function `create_network()` to see how a regression network has been created. Can you explain why the input and output layers have only one node?\n",
    "\n",
    "Now, review the main training loop in the function: `train()`. See how the main loop interates over the many epochs (each epoch is one complete cycle through the data, while learning). Furthermore, note how there is an inner loop of learning, which works only with a mini-batch from the data-loader.\n",
    "\n",
    "### Different activation  functions\n",
    "\n",
    "Which activation function is the `UnivariateApproximator` using? Replace it with some other activation functions, and see how it affects the speed of training, as well as the final model quality (loss).\n",
    "\n",
    "### Different learning rates\n",
    "\n",
    "What is the learning rate in the `UnivariateApproximator`? What would happen if you increase or decrease the learning rate by a few orders of magnitude? Try it out, and discuss the results in our course slack channel.\n",
    "\n",
    "### Structure of the neural network\n",
    "\n",
    "What would happen if you either increase or decrease the number of layers in the neural network? In particular, what would happen if you consider a network with only one hidden layer? Try and find out. Can you get good results with only one layer? If so, what do you observe about the number of nodes you built that layer from?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
