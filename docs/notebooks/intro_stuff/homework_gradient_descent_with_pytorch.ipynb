{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3494de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0918ee",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "\n",
    "Objective: In this exercise, you will complete the implementation of the gradient descent optimization algorithm. The function gradient_descent has been partially provided with comments and a docstring to guide you. Your task is to fill in the missing code sections to complete the function.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    " - **Review the Provided Code**: Examine the partially implemented gradient_descent function. Comments and a docstring have been added to describe what each part of the code should accomplish.\n",
    "\n",
    " - **Complete the Function**: Fill in the missing code as indicated by the comments.\n",
    "\n",
    " - **Test Your Implementation**: Once you've completed the function, test it with the sample objective function provided to ensure it works correctly. Verify that the optimization process converges as expected.\n",
    "\n",
    "This exercise will help you apply the concepts of learnt in class and solidify your understanding of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: torch.tensor) -> torch.tensor:\n",
    "    return (x**2 + 3*x + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077647d6",
   "metadata": {},
   "source": [
    "## Plot the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor 'Xs' with 100 evenly spaced values from -5 to 5,\n",
    "Xs = torch.linspace(start=-5, end=5, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ac489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot f(Xs) vs Xs\n",
    "plt.plot(Xs, f(Xs));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9d253",
   "metadata": {},
   "source": [
    "Fill in the missing code of the `gradient_descent` function given below. Refer section 1.3 of the `Inside Deep Learning` book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5256802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def gradient_descent(x: torch.Tensor, eta: float, epsilon: float, func) -> Tuple[torch.Tensor, list]:\n",
    "    \"\"\"\n",
    "    Performs gradient descent optimization to minimize a given function.\n",
    "\n",
    "    This function iteratively updates the input tensor `x` by taking steps in the direction of the negative gradient \n",
    "    of the specified function `func`. The process continues until the change in the value of `x` is smaller than the \n",
    "    specified tolerance `epsilon`. The function also logs the values of `x` at each step.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): The initial tensor to optimize. This tensor should require gradients.\n",
    "        eta (float): The learning rate for the gradient descent.\n",
    "        epsilon (float): The convergence threshold. The optimization stops when the change in `x` is less than this value.\n",
    "        func (Callable): The function to minimize. \n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, list]: The optimized tensor and a log of tensor values at each step of the optimization.\n",
    "    \"\"\"\n",
    "    # Initialize x_min to the initial value of x. This will be updated during gradient descent.\n",
    "    x_min: torch.Tensor = x.clone()\n",
    "\n",
    "    # Initialize x_min_prev to a large value to start the optimization loop.\n",
    "    x_min_prev = x_min * 100\n",
    "\n",
    "    # List to log the values of x during the optimization process.\n",
    "    learning_log = []\n",
    "    \n",
    "    # Iterate until the change in x is smaller than the tolerance epsilon.\n",
    "    while torch.linalg.norm(x_min - x_min_prev) > epsilon:\n",
    "        x_min_prev = x_min.clone()\n",
    "\n",
    "        # Apply the function to x\n",
    "\n",
    "\n",
    "        # Perform backpropagation.\n",
    "        \n",
    "        \n",
    "        # Update x by taking a step in the direction of the negative gradient.\n",
    "        x = None\n",
    "\n",
    "        # Zero the gradients of x to prepare for the next iteration.\n",
    "        \n",
    "\n",
    "        # Update x_min with the new value of x.\n",
    "        x_min = None\n",
    "\n",
    "        # Log the current value of x.\n",
    "        learning_log.append(x_min.detach().clone().numpy())\n",
    "\n",
    "    return x_min, learning_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor x with a single value of your choice and turn on the gradient tracking\n",
    "x = torch.tensor([10.0], requires_grad=True)\n",
    "\n",
    "# Learning rate\n",
    "eta=0.001\n",
    "\n",
    "# Set a small value to decide how close you want to go to the argmin  \n",
    "epsilon=1e-5\n",
    "\n",
    "argmin, learning_log = gradient_descent(x, eta, epsilon, f)\n",
    "\n",
    "print(argmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acccd7b",
   "metadata": {},
   "source": [
    "Finally lets see how the value of x_min has changed at each step of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f45c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learning_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
