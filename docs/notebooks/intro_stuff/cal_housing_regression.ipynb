{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../images/logo-poster.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first neural architecture\n",
    "\n",
    "We will build a simple neural architecture to solve a problem in linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T04:52:43.740000Z",
     "start_time": "2020-09-17T04:52:43.735673Z"
    }
   },
   "outputs": [],
   "source": [
    "from svlearn.approximator.regression_network import SimpleFeedForwardNet, \\\n",
    "                                                    SimpleNumpyDataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent\n",
    "\n",
    "We will use the california housing dataset for building this neural network regression model\n",
    "\n",
    "## Homework \n",
    "\n",
    "Study the preprocess_data to understand the transformations being done on the ingested raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from svlearn.california_housing.pre_process import preprocess_data\n",
    "from svlearn.california_housing.ingest_data import ingest_cal_housing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ingest_cal_housing_data()\n",
    "preprocessed_data = preprocess_data(data)\n",
    "x = preprocessed_data.drop(['y_target'], axis=1).to_numpy(dtype=np.float32)\n",
    "y = preprocessed_data[['y_target']].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T04:52:45.618029Z",
     "start_time": "2020-09-17T04:52:45.614462Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_x = x.shape[1]\n",
    "X_tensor = torch.from_numpy(x).reshape(-1, dim_x)\n",
    "y_tensor = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T05:03:48.130837Z",
     "start_time": "2020-09-17T05:03:46.241214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the training parts ready\n",
    "network = SimpleFeedForwardNet(input_dimension=dim_x, output_dimension=1)\n",
    "print(network)\n",
    "network.activation = torch.relu # Rectified Linear Unit\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "# Let us now train the network\n",
    "losses = []\n",
    "epochs = 2001\n",
    "drop_out = 0.1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optimizer.zero_grad()  # reset the gradients\n",
    "    results = network(X_tensor, drop_out)  # get predictions\n",
    "    loss = loss_function(results, y_tensor)  # estimate loss\n",
    "    loss.backward()  # back-propagate gradients\n",
    "    optimizer.step()  # update the parameter values (gradient-descent)\n",
    "    losses.append(loss.data)  # keep track of the loss of this epoch\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T00:35:43.705883Z",
     "start_time": "2020-09-17T00:35:43.704456Z"
    }
   },
   "source": [
    "### Plot the results of batch gradient descent on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T05:03:55.016166Z",
     "start_time": "2020-09-17T05:03:54.845171Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from svlearn.approximator.regression_network import create_plots\n",
    "\n",
    "create_plots(epochs, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent\n",
    "\n",
    "Here, at each step, we learn from from mini batches of data. So, for this, the dataloader returns data in small batches. The mini-batch size is specified in the pytorch dataloader by the parameter `batch_size`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T05:07:33.760391Z",
     "start_time": "2020-09-17T05:07:07.619833Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SimpleNumpyDataset(x, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "epochs = 101\n",
    "drop_out = 0.1\n",
    "# Get the training parts ready\n",
    "network = SimpleFeedForwardNet(input_dimension=dim_x, output_dimension=1)\n",
    "print(network)\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(network.parameters(), lr=0.001)\n",
    "losses = []\n",
    "steps = 0\n",
    "for epoch in range(epochs):\n",
    "    start = True\n",
    "    for data, labels in loader:\n",
    "        optimizer.zero_grad()  # reset the parameter gradients\n",
    "        results = network(data, drop_out)  # get predictions\n",
    "        loss = loss_function(results, labels)  # estimate loss\n",
    "        loss.backward()  # back-propagate gradients\n",
    "        optimizer.step()  # update the parameter values (gradient-descent)\n",
    "        losses.append(loss.data)  # keep track of the loss of this epoch\n",
    "        if epoch % 100 == 0 and start:\n",
    "            print('epoch {}, loss {}'.format(epoch, loss.data))\n",
    "        start = False\n",
    "        steps +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us now see how well the model has learned from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of MINI-BATCH gradient descent on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T01:07:35.519479Z",
     "start_time": "2020-09-17T01:07:35.278162Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plots(steps, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Here, each step of learning is from one datum. So an epoch will have as many steps as the training sample size. Let us see how well it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T01:18:41.899757Z",
     "start_time": "2020-09-17T01:12:10.276371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note how we have set the mini-batch size to 1!\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "epochs = 50\n",
    "drop_out = 0.1\n",
    "# Get the training parts ready\n",
    "network = SimpleFeedForwardNet(input_dimension=dim_x, output_dimension=1)\n",
    "\n",
    "print(network)\n",
    "loss_function = MSELoss()\n",
    "optimizer = SGD(network.parameters(), lr=0.001)\n",
    "losses = []\n",
    "steps = 0\n",
    "for epoch in range(epochs):\n",
    "    start = True\n",
    "    for data, labels in loader:\n",
    "        optimizer.zero_grad()  # reset the parameter gradients\n",
    "        results = network(data, drop_out)  # get predictions\n",
    "        loss = loss_function(results, labels)  # estimate loss\n",
    "        loss.backward()  # back-propagate gradients\n",
    "        optimizer.step()  # update the parameter values (gradient-descent)\n",
    "        losses.append(loss.data)  # keep track of the loss of this epoch\n",
    "        if epoch % 5 == 0 and start:\n",
    "            print('epoch {}, loss {}'.format(epoch, loss.data))\n",
    "        start = False\n",
    "        steps +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note how slow the training has gone, since we now have a huge number of steps.**\n",
    "\n",
    "### Let us now see how effective the SGD optimizer has been"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of Stochastic gradient descent optimization based learning from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T01:18:43.745865Z",
     "start_time": "2020-09-17T01:18:41.906011Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plots(steps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
