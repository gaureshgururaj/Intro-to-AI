{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"Neural Architectures\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples have been taken from the sentence transformers [website](https://sbert.net/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The new movie is awesome\",\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"The new movie is so great\",\n",
    "    \"A man is singing\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for both lists\n",
    "embeddings1 = model.encode(sentences1)\n",
    "embeddings2 = model.encode(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarities\n",
    "similarities = model.similarity(embeddings1, embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome\n",
      " - The dog plays in the garden   : 0.0543\n",
      " - The new movie is so great     : 0.8939\n",
      " - A man is singing              : -0.0529\n",
      "The cat sits outside\n",
      " - The dog plays in the garden   : 0.2838\n",
      " - The new movie is so great     : -0.0029\n",
      " - A man is singing              : 0.0048\n",
      "A man is playing guitar\n",
      " - The dog plays in the garden   : 0.2277\n",
      " - The new movie is so great     : -0.0136\n",
      " - A man is singing              : 0.4014\n"
     ]
    }
   ],
   "source": [
    "# Output the pairs with their score\n",
    "for idx_i, sentence1 in enumerate(sentences1):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(sentences2):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus with example sentences\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"convert_to_tensor=True\" to keep the tensors on GPU (if available)\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sentences:\n",
    "queries = [\n",
    "    \"A man is eating pasta.\",\n",
    "    \"Someone in a gorilla costume is playing a set of drums.\",\n",
    "    \"A cheetah chases prey on across a field.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: A man is eating pasta.\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.7035)\n",
      "A man is eating a piece of bread. (Score: 0.5272)\n",
      "A man is riding a horse. (Score: 0.1889)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1047)\n",
      "A cheetah is running behind its prey. (Score: 0.0980)\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.6433)\n",
      "A woman is playing violin. (Score: 0.2564)\n",
      "A man is riding a horse. (Score: 0.1389)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1191)\n",
      "A cheetah is running behind its prey. (Score: 0.1080)\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.8253)\n",
      "A man is eating food. (Score: 0.1399)\n",
      "A monkey is playing drums. (Score: 0.1292)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1097)\n",
      "A man is riding a horse. (Score: 0.0650)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    similarity_scores = model.similarity(query_embedding, corpus_embeddings)[0]\n",
    "    scores, indices = torch.topk(similarity_scores, k=top_k)\n",
    "\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"Top 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(scores, indices):\n",
    "        print(corpus[idx], f\"(Score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 0, 'score': 0.7035485506057739},\n",
       "  {'corpus_id': 1, 'score': 0.5271987915039062},\n",
       "  {'corpus_id': 3, 'score': 0.18889553844928741},\n",
       "  {'corpus_id': 6, 'score': 0.10469925403594971},\n",
       "  {'corpus_id': 8, 'score': 0.09803036600351334},\n",
       "  {'corpus_id': 7, 'score': 0.08189043402671814},\n",
       "  {'corpus_id': 4, 'score': 0.033593934029340744},\n",
       "  {'corpus_id': 5, 'score': -0.059434909373521805},\n",
       "  {'corpus_id': 2, 'score': -0.0898006483912468}],\n",
       " [{'corpus_id': 7, 'score': 0.6432534456253052},\n",
       "  {'corpus_id': 4, 'score': 0.25641557574272156},\n",
       "  {'corpus_id': 3, 'score': 0.13887259364128113},\n",
       "  {'corpus_id': 6, 'score': 0.11909155547618866},\n",
       "  {'corpus_id': 8, 'score': 0.10798681527376175},\n",
       "  {'corpus_id': 0, 'score': 0.06300698965787888},\n",
       "  {'corpus_id': 2, 'score': 0.024657873436808586},\n",
       "  {'corpus_id': 1, 'score': 0.021567005664110184},\n",
       "  {'corpus_id': 5, 'score': -0.08950330317020416}],\n",
       " [{'corpus_id': 8, 'score': 0.8253214359283447},\n",
       "  {'corpus_id': 0, 'score': 0.1398952603340149},\n",
       "  {'corpus_id': 7, 'score': 0.12919358909130096},\n",
       "  {'corpus_id': 6, 'score': 0.10974165052175522},\n",
       "  {'corpus_id': 3, 'score': 0.06497802585363388},\n",
       "  {'corpus_id': 1, 'score': 0.034424010664224625},\n",
       "  {'corpus_id': 2, 'score': 0.015606672503054142},\n",
       "  {'corpus_id': 5, 'score': -0.015542415902018547},\n",
       "  {'corpus_id': 4, 'score': -0.03342076763510704}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "corpus_embeddings = corpus_embeddings.to(\"cuda\")\n",
    "corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
    "\n",
    "query_embeddings = model.encode(queries, convert_to_tensor=True)\n",
    "query_embeddings = query_embeddings.to(\"cuda\")\n",
    "query_embeddings = util.normalize_embeddings(query_embeddings)\n",
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, score_function=util.dot_score)\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vectors, we can also handle other downstream tasks such as classification or clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculates a similarity score given pairs of texts.\n",
    "- Generally provides superior performance compared to a Sentence Transformer (a.k.a. bi-encoder) model.\n",
    "- Often slower than a Sentence Transformer model, as it requires computation for each pair rather than each text.\n",
    "- Due to the previous 2 characteristics, Cross Encoders are often used to re-rank the top-k results from a Sentence Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load a pre-trained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.607138, -4.320078], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. Predict scores for a pair of sentences\n",
    "scores = model.predict([\n",
    "    (\"How many people live in Berlin?\", \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\"),\n",
    "    (\"How many people live in Berlin?\", \"Berlin is well known for its museums.\"),\n",
    "])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Rank a list of passages for a query\n",
    "query = \"How many people live in Berlin?\"\n",
    "passages = [\n",
    "    \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\",\n",
    "    \"Berlin is well known for its museums.\",\n",
    "    \"In 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\",\n",
    "    \"The urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\",\n",
    "    \"The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\",\n",
    "    \"An estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\",\n",
    "    \"Berlin is subdivided into 12 boroughs or districts (Bezirke).\",\n",
    "    \"In 2015, the total labour force in Berlin was 1.85 million.\",\n",
    "    \"In 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\",\n",
    "    \"Berlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\",\n",
    "]\n",
    "ranks = model.rank(query, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many people live in Berlin?\n",
      "8.92\tThe urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\n",
      "8.61\tBerlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\n",
      "8.24\tAn estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\n",
      "7.60\tIn 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\n",
      "6.35\tIn 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\n",
      "5.42\tBerlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\n",
      "3.45\tIn 2015, the total labour force in Berlin was 1.85 million.\n",
      "0.33\tBerlin is subdivided into 12 boroughs or districts (Bezirke).\n",
      "-4.24\tThe city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\n",
      "-4.32\tBerlin is well known for its museums.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the scores\n",
    "print(\"Query:\", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{passages[rank['corpus_id']]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
